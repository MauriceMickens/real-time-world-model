{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 1: Asynchronous vs Synchronous Execution\n",
        "\n",
        "**Focus:** Understanding CPU orchestration vs GPU execution\n",
        "\n",
        "## Objectives\n",
        "- Understand asynchronous execution on GPUs\n",
        "- See the difference between sync and async operations\n",
        "- Learn where CPU and GPU time is spent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: Synchronous Execution\n",
        "\n",
        "Using `torch.cuda.synchronize()` to block CPU until GPU completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create some data\n",
        "N = 4096\n",
        "A = torch.randn((N, N), device='cuda', dtype=torch.float16)\n",
        "B = torch.randn((N, N), device='cuda', dtype=torch.float16)\n",
        "\n",
        "# Synchronous: CPU waits for GPU\n",
        "start = time.time()\n",
        "C = A @ B\n",
        "torch.cuda.synchronize()  # Block until GPU completes\n",
        "sync_time = time.time() - start\n",
        "\n",
        "print(f\"Synchronous execution time: {sync_time*1000:.3f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Asynchronous Execution\n",
        "\n",
        "Without synchronization - CPU continues immediately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asynchronous: CPU continues immediately\n",
        "start = time.time()\n",
        "C = A @ B\n",
        "# No synchronization - GPU work is queued but not waited for\n",
        "async_time = time.time() - start\n",
        "\n",
        "print(f\"Asynchronous (queued) time: {async_time*1000:.3f} ms\")\n",
        "print(f\"Difference: {(sync_time - async_time)*1000:.3f} ms\")\n",
        "print(\"\\nNote: CPU time is much shorter with async, but GPU work still happens!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Observations\n",
        "\n",
        "**Questions to answer:**\n",
        "1. Which time measurement is more accurate for GPU execution time?\n",
        "2. Why is the async time so much shorter?\n",
        "3. When would you want to use sync vs async?\n",
        "\n",
        "_Record your observations here after running the experiments._"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
