{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 2: CUDA Event Timing\n",
        "\n",
        "**Focus:** Using `torch.cuda.Event` for accurate GPU timing\n",
        "\n",
        "## Objectives\n",
        "- Use CUDA events for ground-truth GPU timing\n",
        "- Compare CPU wall-clock time vs GPU event time\n",
        "- Understand why CUDA events are needed for accurate measurements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment: CPU Time vs GPU Event Time\n",
        "\n",
        "Compare `time.time()` with `torch.cuda.Event` timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 4096\n",
        "A = torch.randn((N, N), device='cuda', dtype=torch.float16)\n",
        "B = torch.randn((N, N), device='cuda', dtype=torch.float16)\n",
        "\n",
        "# CPU wall-clock time (with sync)\n",
        "cpu_start = time.time()\n",
        "C = A @ B\n",
        "torch.cuda.synchronize()\n",
        "cpu_time = (time.time() - cpu_start) * 1000  # ms\n",
        "\n",
        "# GPU event time (ground truth)\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start_event.record()\n",
        "C = A @ B\n",
        "end_event.record()\n",
        "torch.cuda.synchronize()  # Wait for events to complete\n",
        "gpu_time = start_event.elapsed_time(end_event)  # ms\n",
        "\n",
        "print(f\"CPU wall-clock time (with sync): {cpu_time:.3f} ms\")\n",
        "print(f\"GPU event time:                  {gpu_time:.3f} ms\")\n",
        "print(f\"Difference:                      {abs(cpu_time - gpu_time):.3f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multiple Iterations\n",
        "\n",
        "Time multiple operations to get stable measurements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WARMUP = 5\n",
        "ITERS = 10\n",
        "\n",
        "# Warmup\n",
        "for _ in range(WARMUP):\n",
        "    _ = A @ B\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# Timed iterations with events\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start_event.record()\n",
        "for _ in range(ITERS):\n",
        "    _ = A @ B\n",
        "end_event.record()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "avg_time = start_event.elapsed_time(end_event) / ITERS\n",
        "\n",
        "print(f\"Average GEMM time ({ITERS} iterations): {avg_time:.3f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Observations\n",
        "\n",
        "**Questions to answer:**\n",
        "1. Why do CUDA events give more accurate GPU timing?\n",
        "2. When would CPU time be misleading?\n",
        "3. What overhead does `synchronize()` add?\n",
        "\n",
        "_Record your observations here after running the experiments._"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
